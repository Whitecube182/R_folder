---
title: "Emerging Markets indecies correlation to GDP"
subtitle: "An exploration into four emerging markets. This paper will explore the correlation of FTSE indicies and GDP."
author: "Even Oscar Harlert"
date: 10/18/2023
format: pdf
---

## Introduction

Emerging markets can be great investment opportunity. In order to make good investment decisions and understand the risk and return for any investment you have to analyze historical data.

To measure countries development there are several metrics that can be useful. In this paper we will keep things simple and only use two metrics and that is gross domestic product (GDP onwards) and population. We could use a lot more metrics but to limit the scope of this paper we are only using GDP and population.

In total we are considering indicies (including a benchmark of FTSE world), GDP and population. Even though the amount of data is small we hope to derive some interesting insights.

## Research question

This paper will have a limited scope. We are seeking to investigate indices data representing each country. The countries selected for this paper are India, Egypt, China and Brazil. Furthermore we

-   How has the historical development been in indices funds been in India, Egypt, China and Brazil?

-   What has the historical risk been?

-   What degree of correlation does the indices have with the GDP for each country?

-   How does correlation between the indices, GDP and population size?

In this paper, we consider risk to be standard deviation of the dataset for the indices.

## Data sets

There are three datasets we have acquired for this paper. The first one is downloaded from [refinitive/datastream](https://www.refinitiv.com/en). For more information regarding the data provider you can follow this [link](https://www.refinitiv.com/content/dam/marketing/en_us/documents/fact-sheets/datastream-economic-data-macro-research-fact-sheet.pdf). This will be refereed to as dataset one. The data in the file are time-series spanning from 19. September 2003 to 19. September 2023. The measurements are done with a monthly interval. All data points are represented in US dollar.

The second data set is downloaded from The World Bank. The data-set is actually divide into two files but will be combined in RStudio as they each only contain one metric of data, GDP and population.

## Project libraries

This project will make use of several libraries in RStudio. The following code snippet will load all the necessary libraries for this project.

```{r}
library(here)
library(tidyverse)
library(readxl)
library(psych)
library(janitor)
library(readxl)
library(ggplot2)
library(reshape2)
```

**NB! We will add any library we add and check it at the end to assure that the project is not missing any dependencies.**

With all the libraries loaded we are ready to start working with our data sets. To be able to replicate the current sets, I have made a github repository where you can access the files. These can be accessed [here](https://github.com/Whitecube182/BUS350). Dataset two is accessible from [World Bank DataBank](https://data.worldbank.org/indicator). However, the refinitive dataset would required you to have a refinitive account. Therefore, to assure that the project is reproducible I made the repository linked above.

In all, we have three excel files in the folder data sets that can be accessed in the project folder.

## Import, tidy & transformation

This section will be split into three sections:

1.  Import, tidy and transform dataset one

2.  Import tidy and transform dataset two

3.  We join the datasets into dataframes we can use for visualzation and modelling.

## Dataset one

Initially we want to start to access the data we collected in the dataset folder. The data is stored as a excel file that has been stored in the project folder. To make it possible to work with in RStudio we start by importing the file and adding the data into a data-frame called index_emerging_markets.

```{r}
index_emerging_markets <- read_excel("datasets/FTSE 20.09.23 - EOH.xlsx", skip = 6)

index_emerging_markets <- index_emerging_markets |>
  rename(
    Date = Name
  )
```

We changed to name of the column for dates to dates from names with the second row. The data in this file is currently in absolute values of the indices. To be able to make comparisons we need to normalize the data with the start of 100. In order to do so we are using the following lines:

```{r}
normalized <- index_emerging_markets |>
  mutate(
    FTSEWorldN = FTSEWorld / (146.2 / 100),
    IndiaN = India / (332.5 / 100),
    EgyptN = Egypt / (59.04 / 100),
    ChinaN = China / (672.28 / 100),
    BrazilN = Brazil / (150.65 / 100),
  )
```

The code above adds 6 new columns where the data is normalized and starts at 100 on the 19. September 2003. The code snippet above can be generalized as the following:

*Initial value / ( Initial value / 100 ). The initial value divided by 100 will be exectued on each of the observation on each row. This results in a graph where we can compare each indicies including our benchmark (FTSE World).*

To save some space we will combine a couple of lines of code:

```{r}
normalized_trimmed <- normalized |>
  select(Date, FTSEWorldN:BrazilN)

normalized_trimmed <- normalized_trimmed |>
  mutate(
    FTSEWorld_Log = c(NA, log(FTSEWorldN[-1] / FTSEWorldN[-nrow(normalized)])),
    India_Log = c(NA, log(IndiaN[-1] / IndiaN[-nrow(normalized)])),
    EgyptN_Log = c(NA, log(EgyptN[-1] / EgyptN[-nrow(normalized)])),
    China_Log = c(NA, log(ChinaN[-1] / ChinaN[-nrow(normalized)])),
    Brazil_Log = c(NA, log(BrazilN[-1] / BrazilN[-nrow(normalized)])),
  )

normalized_trimmed <- normalized_trimmed |>
  mutate(
    FTSE_per = FTSEWorld_Log * 100, 
    India_Per = India_Log * 100,
    Egpyt_per = EgyptN_Log * 100, 
    China_per = China_Log * 100, 
    Brazil_per = Brazil_Log * 100,
  )

log_return <- select(normalized_trimmed,
    -"FTSEWorldN":-"BrazilN"
  )

log_return <- log_return[-1, ]

desc_data <- describe(normalized_trimmed) |>
  t()

desc_data <- as.data.frame(desc_data)

desc_data <- desc_data[-c(1, 5:9), ]

desc_data <- select(desc_data,
                    -"FTSE_per":-"Brazil_per"
                    )

final_desc_data_log <- select(desc_data,
                              FTSEWorld_Log:Brazil_Log
                              )

write.csv(final_desc_data_log, "exported_data/desc_data_log.csv")
```

The lines above does several things, in short:

-   We add rows for log(10) returns (most commonly used while working with historical returns in finance).

-   We create new dataframes that separates data.

-   We use describe() (a function from the psych package), it returns descriptive statistics from the dataset and we store this in a new dataframe called desc_data.

-   A few more selective operations followed by an export to a csv if we at a later point would like to use the descriptive data from the project.

At this point we have dataframes with the data organized to make further analysis later in the project.

As mentioned earlier we used a function called describe, it returns the data in a frame where we have some abbreviations, for anyone not familiar with statistics they are the following:

| Short    | Definition                                                                                                                                                                              |
|------------|------------------------------------------------------------|
| n        | Number of observations                                                                                                                                                                  |
| mean     | The avarage                                                                                                                                                                             |
| sd       | Standard deviation (this is considered risk in financial terms)                                                                                                                         |
| skew     | Skewness is the degree of asymmetry observed in a probability distribution ([source](Skewness%20is%20the%20degree%20of%20asymmetry%20observed%20in%20a%20probability%20distribution.)). |
| kurtosis | An indicator of the tail of the distribution ([source](https://www.investopedia.com/terms/k/kurtosis.asp)).                                                                             |
| se       | Standard error, and estimation of the standard deviation.                                                                                                                               |

: Furthermore, all this data is contextual and even though it does not provide any direct information to answer our research questions it does provide information about the data set. The skew indicates if the return are aligning more on the left of or the right side of the distribution. The kurtosis are relevant due to indicating extreme values deviating from the mean. In financial terms this would be extreme profit or loss. The risk (standard deviation) and the mean (return) are directly related to the question.

## Dataset two

The second dataset is actually two excel files downloaded from the World Bank. Again, we need to load the data into a dataframe:

```{r}
countries <- c("India", "Egypt, Arab Rep.", "China", "Brazil")

gdp <- read_excel("datasets/gdp.xls", skip = 3)

population <- read_excel("datasets/population.xls", skip = 3)
```

In addition to loading two dataframes with the data from the files, we also stored the four values (the names of the countries we are working with.

The datsets are filled with data we do not have any use for therefore we need to tidy it:

```{r}
gdp <- clean_names(gdp)
population <- clean_names(population)

gdp_clean <- select(gdp,
  -"x1960":-"x2002",
  -"indicator_code",
  -"indicator_name",
  -"country_code"
  ) |>
  filter(
    country_name %in% countries
  ) |>
  t() |>
  row_to_names(row_number = 1) |>
  as.data.frame()

population_clean <- select(population,
  -"x1960":-"x2002",
  -"indicator_code",
  -"indicator_name",
  -"country_code"
  ) |> 
  filter(
    country_name %in% countries
  ) |>
  t() |>
  row_to_names(row_number = 1) |>
  as.data.frame()

population_clean <- population_clean %>%
  rownames_to_column(var="Date")

population_clean <- population_clean %>%
  rownames_to_column(var="Date")
population_clean$Date <- sub("^x", "", population_clean$Date)
names(population_clean)[4] <- "Egypt"

gdp_clean <- gdp_clean %>%
  rownames_to_column(var="Date")
gdp_clean$Date <- sub("^x", "", gdp_clean$Date)
names(gdp_clean)[4] <- "Egypt"

population_clean$Brazil <- as.numeric(population_clean$Brazil)
population_clean$China <- as.numeric(population_clean$China)
population_clean$Egypt <- as.numeric(population_clean$Egypt)
population_clean$India <- as.numeric(population_clean$India)
population_clean$Date <- as.numeric(population_clean$Date)

gdp_clean$Brazil <- as.numeric(gdp_clean$Brazil)
gdp_clean$China <- as.numeric(gdp_clean$China)
gdp_clean$Egypt <- as.numeric(gdp_clean$Egypt)
gdp_clean$India <- as.numeric(gdp_clean$India)
gdp_clean$Date <- as.numeric(gdp_clean$Date)

gdp_clean_long <- pivot_longer(gdp_clean, cols = -Date, names_to = "Country", values_to = "GDP")
gdp_clean_long$Date <- as.numeric(gdp_clean_long$Date)

population_clean_long <- pivot_longer(population_clean, cols = -Date, names_to = "Country", values_to = "Population")
population_clean_long$Date <- as.numeric(population_clean_long$Date)
```

Above we are simply cleaning out and making usable data frames for later in the project and for future visualization. We also assure that the data is in its correct form,

## Join data set 1 & 2

Join dataset 1 & 2

## Visualzation

Until now we only have several dataframes and descriptive statistics from the datasets. In this section we will visualize the data to improve our understanding of what the data represent.

The first thing we want to get a better overveiw over is dataset one.

The normalized development of the FTSE Indicies can simply be graph it out doing the following:

```{r}
ggplot(
  data = normalized_trimmed,
  mapping = aes(x = Date, y = FTSEWorldN )
) +
  geom_line( mapping = aes())

ggplot(
  data = normalized_trimmed,
  mapping = aes(x = Date, y = IndiaN )
) +
  geom_line( mapping = aes())

ggplot(
  data = normalized_trimmed,
  mapping = aes(x = Date, y = EgyptN )
) +
  geom_line( mapping = aes())

ggplot(
  data = normalized_trimmed,
  mapping = aes(x = Date, y = ChinaN )
) +
  geom_line( mapping = aes())

ggplot(
  data = normalized_trimmed,
  mapping = aes(x = Date, y = BrazilN )
) +
  geom_line( mapping = aes())


```

The returns combined in one image resuluts in the following:

```{r}

ggplot(
  data = normalized_trimmed,
  mapping = aes(x = Date)
) +
  geom_line(aes(y = FTSEWorldN, color = "FTSEWorldN")) +
  geom_line(aes(y = IndiaN, color = "IndiaN")) +
  geom_line(aes(y = EgyptN, color = "EgyptN")) +
  geom_line(aes(y = ChinaN, color = "ChinaN")) +
  geom_line(aes(y = BrazilN, color = "BrazilN")) +
  scale_color_manual(values = c("FTSEWorldN" = "red", "IndiaN" = "green", "EgyptN" = "blue", "ChinaN" = "orange", "BrazilN" = "purple")) +
  labs(
    title = "Geometric eturns 20 years",
    x = "Date",
    y = "Return",
    color = "Countries"
  ) +
  theme_minimal()

```
